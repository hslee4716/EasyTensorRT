{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers.models.gpt_neox import GPTNeoXTokenizerFast\n",
    "from easytrt import TRTBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
      "The class this function is called from is 'GPTNeoXTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/05/2023-04:46:14] [TRT] [I] Loaded engine size: 32644 MiB\n",
      "[09/05/2023-04:46:30] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +32594, now: CPU 0, GPU 32594 (MiB)\n",
      "[09/05/2023-04:46:40] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +1126, now: CPU 0, GPU 33720 (MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3018336/2836643043.py:43: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  dtype = self.engine.get_binding_dtype(i)\n",
      "/tmp/ipykernel_3018336/2836643043.py:45: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  if self.engine.binding_is_input(i):\n",
      "/tmp/ipykernel_3018336/2836643043.py:46: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  cur_binding_shape = self.engine.get_binding_shape(i)\n",
      "/tmp/ipykernel_3018336/2836643043.py:49: DeprecationWarning: Use get_tensor_profile_shape instead.\n",
      "  profile_shape = self.engine.get_profile_shape(0, i)\n",
      "/tmp/ipykernel_3018336/2836643043.py:51: DeprecationWarning: Use set_input_shape instead.\n",
      "  self.context.set_binding_shape(i, tuple(profile_shape[2]))\n",
      "/tmp/ipykernel_3018336/2836643043.py:52: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  shape = tuple(self.context.get_binding_shape(i))\n",
      "/tmp/ipykernel_3018336/2836643043.py:65: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  if self.engine.binding_is_input(i):\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "tokenizer = GPTNeoXTokenizerFast.from_pretrained('nlpai-lab/kullm-polyglot-12.8b-v2')\n",
    "model = TRTBackend(\"/home/team_ai/JMJ/nlp_model/kullm_dev/HS/kullm_12.8b.engine\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]]\n",
      "0.03949475288391113\n",
      "[',,,,,,,,,,,,,,,,,,,,,,']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3013476/2836643043.py:97: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  nshape = self.context.get_binding_shape(out[\"index\"])\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    t = time()\n",
    "    inputs = tokenizer(\"im stylish, black top big T-shirts billie\", return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids\n",
    "    masks = torch.ones_like(input_ids)\n",
    "    input_ids, masks\n",
    "    output = model([input_ids, masks])[-1]\n",
    "    output_np = output.detach().cpu().numpy()\n",
    "\n",
    "    output_ids = np.argmax(output_np, 2)\n",
    "    output = tokenizer.batch_decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    print(time()-t)\n",
    "    # print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kullm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
